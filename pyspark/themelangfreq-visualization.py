# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-L10EEfjC-dNk1BwVCLYvpHSdaR6FcAU
"""

!pip install pyspark

from pyspark.sql import SparkSession
from pyspark.sql.functions import split, col, sum as _sum
import plotly.express as px
import pandas as pd

# Initialize Spark
spark = SparkSession.builder.appName("Theme-Frequency-By-Language").getOrCreate()

# 1. Load and parse the data (replace with your actual file)
df = spark.read.text("part-r-00000")

# 2. Parse into columns (Language, Theme, Count)
parsed_df = df.withColumn("temp", split(col("value"), " - ")) \
              .withColumn("language", col("temp")[0]) \
              .withColumn("theme_count", split(col("temp")[1], "\t")) \
              .withColumn("theme", col("theme_count")[0]) \
              .withColumn("count", col("theme_count")[1].cast("integer")) \
              .drop("value", "temp", "theme_count")

# 3. Group by Theme and aggregate counts
theme_groups = parsed_df.groupBy("theme").agg(_sum("count").alias("total_count"))

# Get list of themes
themes = [row.theme for row in theme_groups.select("theme").collect()]

# 4. Create pie charts for each theme
for theme in themes:
    # Get the data for this theme
    theme_data = parsed_df.filter(col("theme") == theme) \
                         .select("language", "count") \
                         .toPandas()

    # Sort by count descending
    theme_data = theme_data.sort_values('count', ascending=False)

    if len(theme_data) > 5:  # Only group if more than 5 languages
        top5 = theme_data.head(5)
        others_row = pd.DataFrame({
            'language': ['Others'],
            'count': [theme_data['count'][5:].sum()]
        })
        theme_data = pd.concat([top5, others_row])

    # Create the pie chart
    fig = px.pie(theme_data,
                 values='count',
                 names='language',
                 title=f'Top Languages for "{theme}" Theme',
                 hover_data=['count'],
                 hole=0.3)

    fig.update_traces(
        textposition='inside',
        textinfo='percent+label',
        insidetextfont=dict(size=12, color='white'),
        hovertemplate="<b>%{label}</b><br>Count: %{value}<br>Percent: %{percent}"
    )

    fig.update_layout(
        uniformtext_minsize=10,
        uniformtext_mode='hide',
        height=600,
        showlegend=False
    )

    fig.show()

# 5. Show overall theme distribution
total_counts = theme_groups.orderBy("total_count", ascending=False).toPandas()
fig = px.pie(total_counts,
             values='total_count',
             names='theme',
             title='Overall Theme Distribution',
             hover_data=['total_count'])

fig.update_traces(
    textposition='inside',
    textinfo='percent+label',
    insidetextfont=dict(size=12, color='white'),
    hovertemplate="<b>%{label}</b><br>Total Count: %{value}<br>Percent: %{percent}"
)

fig.update_layout(
    height=700,
    showlegend=False
)

fig.show()

# Stop Spark
spark.stop()



